{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35573ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data\n",
    "data = pd.read_csv('stroke_data.csv')\n",
    "#showing the first 5 records of the data set\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724d911",
   "metadata": {},
   "source": [
    "\n",
    "Έχουμε 12 χαρακτηριστικά. Το χαρακτηριστικό id είναι ένας μοναδικός αριθμός που δίνεται σε κάθε ασθενή, οπότε δεν χρειάζεται για την ανάλυσή μας. Για αυτόν τον λόγο διαγράφουμε την συγκεκριμένη στήλη."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac762c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the id attribute column\n",
    "data.drop(columns=['id'],inplace=True)\n",
    "#showing the first 5 records of the data set\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac783e4d",
   "metadata": {},
   "source": [
    "Για τα 11 χαρακτηριστικά που έμειναν έχουμε:\n",
    "\n",
    "**Gender**: Το φύλλο του ασθενούς Male/Female/Other\n",
    "\n",
    "**Age**: Η ηλικία του ασθενούς\n",
    "\n",
    "**Hypertension**: Αν ο ασθενής έχει (1) ή δεν έχει (0) υπέρταση\n",
    "\n",
    "**Heart Disease**: Αν ο ασθενής έχει (1) ή δεν έχει (0) κάποια ασθένεια της καρδιάς\n",
    "\n",
    "**Ever Married**: Αν έχει παντρευτεί ποτέ ο ασθενής Yes/No\n",
    "\n",
    "**Work Type**: Ο τύπος εργασίας του ασθενούς Children/Govt_job/Never_worked/Private/Self-employed\n",
    "\n",
    "**Residence Type**: Περιβάλλος διαβίωσης του ασθενούς Rural/Urban\n",
    "\n",
    "**Average Glucose Level**: Μέσο επίπεδο γλυκόζης στο αίμα του ασθενούς\n",
    "\n",
    "**BMI**: Δείκτης μάζας σώματος του ασθενούς\n",
    "\n",
    "**Smoking Status**: Σχέση του ασθενούς με το κάπνισμα Formerly_smoked/never_smoked/smokes/Unknown\n",
    "\n",
    "**Stroke**: Ο ασθενής είχε (1) ή δεν είχε (0) πάθει εγκεφαλικό. Πρόκειται για τον δείκτη που θέλουμε να προβλέψουμε\n",
    "\n",
    "\n",
    "Πριν προχωρήσουμε στην κατασκευή των δεδομένων πρέπει να κοιτάξουμε αν υπάρχουν ελλιπή δεδομένα, που μπορεί να επηρεάσουν την αποδόση των μοντέλων μας. Αυτό κάνουμε στην συνέχεια."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list with the column/attribute names\n",
    "columns = list(data.columns)\n",
    "#iterating through the data to find NaN values\n",
    "for name in columns:\n",
    "    nans = data.loc[data[name].isna(),name].size\n",
    "    print(f'There are {nans} NaN values in column {name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f256d68",
   "metadata": {},
   "source": [
    "Με βάση το προηγούμενο αποτέλεσμα βλέπουμε ότι NaN τιμές υπάρχουν μόνο στο χαρακτηριστικό που αφορά τον δείκτη μάζας σώματος. Άρα πρέπει να καθαρίσουμε αυτές τις ελλιπείς τιμές. Για να το κάνουμε αυτό αντικαθιστούμε αυτές τις NaN τιμές με την πιό αντιπροσωπευτική τιμή αυτού του χαρακτηριστικού, που είναι η μέση τιμή των υπαρχουσών τιμών."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac40d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#series with the not NaN data values for the attribute BMI\n",
    "not_nan_data = data.loc[data['bmi'].notna(),'bmi']\n",
    "\n",
    "#mean value of the bmi attribute\n",
    "mean_bmi = not_nan_data.mean()\n",
    "\n",
    "#replacing nan values of the bmi attribute with the mean value that we just calculated\n",
    "data['bmi'].fillna(mean_bmi,inplace=True)\n",
    "\n",
    "#checking again if there are NaN values\n",
    "for name in columns:\n",
    "    nans = data.loc[data[name].isna(),name].size\n",
    "    print(f'There are {nans} NaN values in column {name}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9debefe2",
   "metadata": {},
   "source": [
    "# **Stroke**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots about the stroke attribute which we want to predict\n",
    "stroked = len(data.loc[data['stroke']== 1]) #number of lines with Stroke=1\n",
    "not_stroked = len(data.loc[data['stroke'] == 0]) #number of lines with Stroke=0\n",
    "#putting the results in a list\n",
    "stroke_values = [not_stroked,stroked]\n",
    "stroke_labels = ['No Stroke','Stroke'] #labels\n",
    "stroke_explode = [0.1,0.1] #needed for the pie chart\n",
    "#creating a pie chart\n",
    "plt.figure()\n",
    "plt.pie(stroke_values,explode=stroke_explode,labels=stroke_labels,autopct='%1.3f%%')\n",
    "plt.title('Pie chart with the distribution of classes')\n",
    "plt.xlabel(f'Stroke={stroked}, No stroke={not_stroked}')\n",
    "plt.savefig(fname='Stroke_pie_chart.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#creating a bar plot for the 2 class labels\n",
    "plt.figure()\n",
    "plt.bar(['No Stroke','Stroke'],stroke_values,width=0.6)\n",
    "plt.title('Number of rows for each class label')\n",
    "plt.xlabel('0=No stroke, 1=Stroke')\n",
    "plt.savefig(fname='Stroke_bar_plot.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a58599",
   "metadata": {},
   "source": [
    "# **Gender**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5f2591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots about the gender attribute\n",
    "#for the whole data set\n",
    "males = len(data.loc[data['gender']=='Male']) #number of rows with Gender=Male\n",
    "females = len(data.loc[data['gender']=='Female']) #number of rows with Gender=Female\n",
    "other = len(data.loc[data['gender']=='Other']) #number of row with Gender=Other\n",
    "pie_gender_sizes = [males,females,other]\n",
    "gender_labels = ['Male','Female','Other'] #labels\n",
    "explode = [0.075,0.075,0.1] #needed for the pie chart\n",
    "\n",
    "#Pie chart\n",
    "plt.figure()\n",
    "plt.pie(pie_gender_sizes,explode=explode,labels=gender_labels,autopct='%1.5f%%',shadow=True)\n",
    "plt.title('Percentage of genders in the data set')\n",
    "plt.xlabel(f'Males={males}, Females={females}, Other={other}')\n",
    "plt.savefig(fname='genders_pie_all.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with stroke=0\n",
    "males_0 = len(data.loc[(data['gender']=='Male') & (data['stroke']==0)]) \n",
    "females_0 = len(data.loc[(data['gender']=='Female') & (data['stroke']==0)])\n",
    "other_0 = len(data.loc[(data['gender']=='Other') & (data['stroke']==0)])\n",
    "pie_gender_sizes_0 = [males_0,females_0,other_0]\n",
    "\n",
    "#Pie chart\n",
    "plt.figure()\n",
    "plt.pie(pie_gender_sizes_0,explode=explode,labels=gender_labels,autopct='%1.5f%%',shadow=True)\n",
    "plt.title('Percentage of genders without a stroke')\n",
    "plt.xlabel(f'Males={males_0}, Females={females_0}, Other={other_0}')\n",
    "plt.savefig(fname='genders_pie_no_stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for data with stroke=1\n",
    "males_1 = len(data.loc[(data['gender']=='Male') & (data['stroke']==1)])\n",
    "females_1 = len(data.loc[(data['gender']=='Female') & (data['stroke']==1)])\n",
    "other_1 = len(data.loc[(data['gender']=='Other') & (data['stroke']==1)])\n",
    "pie_gender_sizes_1 = [males_1,females_1,other_1]\n",
    "\n",
    "#Pie chart\n",
    "plt.figure()\n",
    "plt.pie(pie_gender_sizes_1,explode=explode,labels=gender_labels,autopct='%1.5f%%',shadow=True)\n",
    "plt.title('Percentage of genders which suffered a stroke')\n",
    "plt.xlabel(f'Males={males_1}, Females={females_1}, Other={other_1}')\n",
    "plt.savefig(fname='genders_pie_stroke.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4b8cab",
   "metadata": {},
   "source": [
    "# **Age**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd88b17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#boxplots for the age attribute\n",
    "all_data = data['age']\n",
    "age_stroke = data.loc[data['stroke']==1,'age'] #age data for patients with Stroke=1\n",
    "age_no_stroke = data.loc[data['stroke']==0,'age'] #age data for patients with Stroke=0\n",
    "age_labels = ['Age','Stroke','No Stroke'] #labels\n",
    "\n",
    "#Creating boxplots for the Age attribute\n",
    "plt.figure()\n",
    "plt.boxplot([all_data,age_stroke,age_no_stroke],labels=age_labels,patch_artist=True,showmeans=True,)\n",
    "plt.ylabel('Age')\n",
    "plt.title('Boxplots for the Age attribute')\n",
    "plt.grid()\n",
    "plt.savefig(fname='age_boxplots.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367427df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median ages\n",
    "stroke_median_age = data['age'].loc[data['stroke']==1].median()\n",
    "print(f'Median age of patients who suffered a stroke: {stroke_median_age}')\n",
    "no_stroke_median_age = data['age'].loc[data['stroke']==0].median()\n",
    "print(f'Median age of patients with no stroke: {no_stroke_median_age}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666e684",
   "metadata": {},
   "source": [
    "Παρατηρούμε ότι οι ασθενείς που έχουν πάθει εγκεφαλικό είναι κατα μέσο όρο μεγάλης ηλικίας σε αντίθεση με αυτούς που δεν έχουν πάθει εγκεφαλικό. Με βάση αυτό καταλαβαίνουμε ότι το χαρακτηριστικό της ηλικίας θα είναι ένας από τους πιό σημαντικούς predictors για τα μοντέλα που θα κατασκευάσουμε. Επίσης αξίζει να σχολιάσουμε ότι στους ασθενέις που έχουν υποστεί εγκεφαλικό υπάρχουν και 2 outliers που αφορούν ασθενείς που έπαθαν το εγκεφαλικό νέοι. Στην συνέχεια εντοπίζουμε τις εγγραφές αυτών των outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e33bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the outliers\n",
    "outlier = data.loc[(data['age']<20) & data['stroke']==1]\n",
    "print(outlier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd9e8c6",
   "metadata": {},
   "source": [
    "Κλινικά δεν είναι σωστό να εμφανίζουν έμφραγμα αυτοί οι ασθενείς, οπότε είναι πολύ πιθανό να έχουν γίνει λάθος καταγραφές. Για αυτόν τον λόγο διαγράφουμε αυτές τις εγγραφές."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2962966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the outliers\n",
    "data.drop(index=[162,245],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd64123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reseting the indices\n",
    "data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63a675e",
   "metadata": {},
   "source": [
    "Ξανακάνουμε τα boxplot για να δούμε ότι δεν υπάρχουν outliers πλέον"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f995d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxplots for the age attribute\n",
    "all_data = data['age']\n",
    "age_stroke = data.loc[data['stroke']==1,'age'] #age data for patients with stroke=1\n",
    "age_no_stroke = data.loc[data['stroke']==0,'age'] #age data for patients with stroke=0\n",
    "age_labels = ['Age','Stroke','No Stroke'] #labels\n",
    "\n",
    "#boxplots for the Age attribute\n",
    "plt.figure()\n",
    "plt.boxplot([all_data,age_stroke,age_no_stroke],labels=age_labels,patch_artist=True,showmeans=True,)\n",
    "plt.ylabel('Age')\n",
    "plt.title('Boxplots for the Age attribute')\n",
    "plt.grid()\n",
    "plt.savefig(fname='age_boxplot_no_outliers.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ff856f",
   "metadata": {},
   "source": [
    "# Hypertension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db753421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the whole data set\n",
    "hypertension = len(data.loc[data['hypertension']==1]) #data with Hypertension=1\n",
    "no_hypertension = len(data.loc[data['hypertension']==0]) #data with Hypertension=0\n",
    "\n",
    "#lists needed for the pie chart\n",
    "pie_hypertension_sizes = [no_hypertension,hypertension]\n",
    "hypertension_labels = ['No Hypertension','Hypertension']\n",
    "explode = [0.075,0.075]\n",
    "\n",
    "#pie chart \n",
    "plt.figure()\n",
    "plt.pie(pie_hypertension_sizes,explode=explode,labels=hypertension_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Hypertension Percentages')\n",
    "plt.xlabel(f'Hypertension={hypertension}, No Hypertension={no_hypertension}')\n",
    "plt.savefig(fname='hypertension_pie_all.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=0\n",
    "hypertension_0 = len(data.loc[(data['hypertension']==1) & (data['stroke']==0)])\n",
    "no_hypertension_0 = len(data.loc[(data['hypertension']==0) & (data['stroke']==0)])\n",
    "pie_hypertension_sizes_0 = [no_hypertension_0,hypertension_0]\n",
    "\n",
    "#pie chart \n",
    "plt.figure()\n",
    "plt.pie(pie_hypertension_sizes_0,explode=explode,labels=hypertension_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Hypertension Percentages for Patients with no stroke')\n",
    "plt.xlabel(f'Hypertension={hypertension_0}, No Hypertension={no_hypertension_0}')\n",
    "plt.savefig(fname='hypertension_pie_no_stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=1\n",
    "hypertension_1 = len(data.loc[(data['hypertension']==1) & (data['stroke']==1)])\n",
    "no_hypertension_1 = len(data.loc[(data['hypertension']==0) & (data['stroke']==1)])\n",
    "pie_hypertension_sizes_1 = [no_hypertension_1,hypertension_1]\n",
    "\n",
    "#pie chart \n",
    "plt.figure()\n",
    "plt.pie(pie_hypertension_sizes_1,explode=explode,labels=hypertension_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Hypertension Percentages for Patients who suffered a stroke')\n",
    "plt.xlabel(f'Hypertension={hypertension_1}, No Hypertension={no_hypertension_1}')\n",
    "plt.savefig(fname='hypertension_pie_stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#bar plots\n",
    "#creating a bar plot for the hypertension Attribute\n",
    "plt.figure()\n",
    "plt.bar(['No Hypertension','Hypertension'],pie_hypertension_sizes,width=0.6)\n",
    "plt.xlabel('0=No hypertension, 1=Hypertension')\n",
    "plt.title('Bar plot for the Hypertension attribute')\n",
    "plt.savefig(fname='hypertension_bar_plot.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70271b7",
   "metadata": {},
   "source": [
    "# Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc21fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the whole data set\n",
    "hd = len(data.loc[data['heart_disease']==1])\n",
    "no_hd = len(data.loc[data['heart_disease']==0])\n",
    "\n",
    "pie_hd_sizes = [no_hd,hd]\n",
    "hd_labels = ['No Heart Disease','Heart Disease']\n",
    "explode = [0.075,0.075]\n",
    "#pie chart \n",
    "plt.figure()\n",
    "plt.pie(pie_hd_sizes,explode=explode,labels=hd_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Heart Disease Percentages')\n",
    "plt.xlabel(f'Heart Disease={hd}, No Heart Disease={no_hd}')\n",
    "plt.savefig(fname='hd_pie_all.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=0\n",
    "hd_0 = len(data.loc[(data['heart_disease']==1) & (data['stroke']==0)])\n",
    "no_hd_0 = len(data.loc[(data['heart_disease']==0) & (data['stroke']==0)])\n",
    "pie_hd_sizes_0 = [no_hd_0,hd_0]\n",
    "\n",
    "#pie chart \n",
    "plt.figure()\n",
    "plt.pie(pie_hd_sizes_0,explode=explode,labels=hd_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Heart disease Percentages for Patients with no stroke')\n",
    "plt.xlabel(f'Heart Disease={hd_0}, No Heart Disease={no_hd_0}')\n",
    "plt.savefig(fname='hd_pie_no_Stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=1\n",
    "hd_1 = len(data.loc[(data['heart_disease']==1) & (data['stroke']==1)])\n",
    "no_hd_1 = len(data.loc[(data['heart_disease']==0) & (data['stroke']==1)])\n",
    "pie_hd_sizes_1 = [no_hd_1,hd_1]\n",
    "\n",
    "#pie chart \n",
    "plt.figure()\n",
    "plt.pie(pie_hd_sizes_1,explode=explode,labels=hd_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Heart disease Percentages for Patients who suffered a stroke')\n",
    "plt.xlabel(f'Heart Disease={hd_1}, No Heart Disease={no_hd_1}')\n",
    "plt.savefig(fname='hd_pie_stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#bar plots\n",
    "#creating a bar plot\n",
    "plt.figure()\n",
    "plt.bar(['No Heart Disease','Heart Disease'],pie_hd_sizes,width=0.6)\n",
    "plt.xlabel('0=No Heart Disease, 1=Heart Disease')\n",
    "plt.title('Bar plot for the Heart Disease attribute')\n",
    "plt.savefig(fname='hd_bar_plot.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adea80fb",
   "metadata": {},
   "source": [
    "# Ever Married"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a20f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for all the data\n",
    "married = len(data.loc[data['ever_married']=='Yes'])\n",
    "single = len(data.loc[data['ever_married']=='No'])\n",
    "pie_sizes = [single,married]\n",
    "pie_labels = ['Never married','Married']\n",
    "explode = [0.00,0.00]\n",
    "\n",
    "#pie chart \n",
    "plt.figure()\n",
    "plt.pie(pie_sizes,explode=explode,labels=pie_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Marriage Percentages')\n",
    "plt.xlabel(f'Married={married}, Never Married={single}')\n",
    "plt.savefig(fname='married_pie_all.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=0\n",
    "married_0 = len(data.loc[(data['ever_married']=='Yes') & (data['stroke']==0)])\n",
    "single_0 = len(data.loc[(data['ever_married']=='No') & (data['stroke']==0)])\n",
    "pie_sizes_0 = [single_0,married_0]\n",
    "\n",
    "plt.figure()\n",
    "plt.pie(pie_sizes_0,explode=explode,labels=pie_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Marriage Percentages for the patients with no stroke')\n",
    "plt.xlabel(f'Married={married_0}, Never Married={single_0}')\n",
    "plt.savefig(fname='married_pie_no_Stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=1\n",
    "married_1 = len(data.loc[(data['ever_married']=='Yes') & (data['stroke']==1)])\n",
    "single_1 = len(data.loc[(data['ever_married']=='No') & (data['stroke']==1)])\n",
    "pie_sizes_1 = [single_1,married_1]\n",
    "\n",
    "plt.figure()\n",
    "plt.pie(pie_sizes_1,explode=explode,labels=pie_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Marriage Percentages for the patients who suffered a stroke')\n",
    "plt.xlabel(f'Married={married_1}, Never Married={single_1}')\n",
    "plt.savefig(fname='married_pie_stroke.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b397650f",
   "metadata": {},
   "source": [
    "# Work Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86dc198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for all the data\n",
    "children = len(data.loc[data['work_type']=='children'])\n",
    "govt = len(data.loc[data['work_type']=='Govt_job'])\n",
    "never = len(data.loc[data['work_type']=='Never_worked'])\n",
    "private = len(data.loc[data['work_type']=='Private'])\n",
    "self = len(data.loc[data['work_type']=='Self-employed'])\n",
    "work_values = [children,govt,never,private,self]\n",
    "work_labels = ['Children','Goverment','Never Worked','Private','Self-Employed']\n",
    "explode=[0,0.15,0.55,0.05,0]\n",
    "#pie chart\n",
    "plt.figure()\n",
    "plt.pie(work_values,explode=explode,labels=work_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Work type percentages',y=1.2)\n",
    "plt.xlabel(f'Children={children}, Goverment={govt}, Never Worked={never}, Private={private}, Self-employed={self}')\n",
    "plt.savefig(fname='work_pie_all.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=0\n",
    "children_0 = len(data.loc[(data['work_type']=='children') & (data['stroke']==0)])\n",
    "govt_0 = len(data.loc[(data['work_type']=='Govt_job') & (data['stroke']==0)])\n",
    "never_0 = len(data.loc[(data['work_type']=='Never_worked') & (data['stroke']==0)])\n",
    "private_0 = len(data.loc[(data['work_type']=='Private') & (data['stroke']==0)]) \n",
    "self_0 = len(data.loc[(data['work_type']=='Self-employed') & (data['stroke']==0)])\n",
    "work_values_0 = [children_0,govt_0,never_0,private_0,self_0]\n",
    "\n",
    "#pie chart\n",
    "plt.figure()\n",
    "plt.pie(work_values_0,explode=explode,labels=work_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Work type percentages for patients with no stroke',y=1.2)\n",
    "plt.xlabel(f'Children={children_0}, Goverment={govt_0}, Never Worked={never_0}, Private={private_0}, Self-employed={self_0}')\n",
    "plt.savefig(fname='work_pie_no_Stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=1\n",
    "children_1 = len(data.loc[(data['work_type']=='children') & (data['stroke']==1)])\n",
    "govt_1 = len(data.loc[(data['work_type']=='Govt_job') & (data['stroke']==1)])\n",
    "never_1 = len(data.loc[(data['work_type']=='Never_worked') & (data['stroke']==1)])\n",
    "private_1 = len(data.loc[(data['work_type']=='Private') & (data['stroke']==1)]) \n",
    "self_1 = len(data.loc[(data['work_type']=='Self-employed') & (data['stroke']==1)])\n",
    "work_values_1 = [children_1,govt_1,never_1,private_1,self_1]\n",
    "\n",
    "#pie chart\n",
    "plt.figure()\n",
    "plt.pie(work_values_1,explode=explode,labels=work_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.title('Work type percentages for patients who suffered stroke',y=1.2)\n",
    "plt.xlabel(f'Children={children_1}, Goverment={govt_1}, Never Worked={never_1}, Private={private_1}, Self-employed={self_1}')\n",
    "plt.savefig(fname='work_pie_stroke.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac9b1c8",
   "metadata": {},
   "source": [
    "# Residence Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for all the data\n",
    "rural = len(data.loc[data['Residence_type']=='Rural'])\n",
    "urban = len(data.loc[data['Residence_type']=='Urban'])\n",
    "rt_values = [rural,urban]\n",
    "rt_labels = ['Rural','Urban']\n",
    "explode=[0,0]\n",
    "#pie chart\n",
    "plt.figure()\n",
    "plt.pie(rt_values,explode=explode,labels=rt_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.xlabel(f'Rural={rural}, Urban={urban}')\n",
    "plt.title('Residence type of the patients')\n",
    "plt.savefig(fname='residence_pie_all.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=0\n",
    "rural_0 = len(data.loc[(data['Residence_type']=='Rural') & (data['stroke']==0)])\n",
    "urban_0 = len(data.loc[(data['Residence_type']=='Urban') & (data['stroke']==0)])\n",
    "rt_values_0 = [rural_0,urban_0]\n",
    "\n",
    "plt.figure()\n",
    "plt.pie(rt_values_0,explode=explode,labels=rt_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.xlabel(f'Rural={rural_0}, Urban={urban_0}')\n",
    "plt.title('Residence Type of patients with no stroke')\n",
    "plt.savefig(fname='residence_pie_no_stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=1\n",
    "rural_1 = len(data.loc[(data['Residence_type']=='Rural') & (data['stroke']==1)])\n",
    "urban_1 = len(data.loc[(data['Residence_type']=='Urban') & (data['stroke']==1)])\n",
    "rt_values_1 = [rural_1,urban_1]\n",
    "\n",
    "plt.figure()\n",
    "plt.pie(rt_values_1,explode=explode,labels=rt_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.xlabel(f'Rural={rural_1}, Urban={urban_1}')\n",
    "plt.title('Residence Type of patients who suffered a stroke')\n",
    "plt.savefig(fname='residence_pie_stroke.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e1f90a",
   "metadata": {},
   "source": [
    "# Smoking status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea97e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for all the data\n",
    "fs = len(data.loc[data['smoking_status']=='formerly smoked'])\n",
    "ns = len(data.loc[data['smoking_status']=='never smoked'])\n",
    "s = len(data.loc[data['smoking_status']=='smokes'])\n",
    "u = len(data.loc[data['smoking_status']=='Unknown'])\n",
    "s_values = [fs,ns,s,u]\n",
    "s_labels = ['Formerly Smoked','Never Smoked','Smokes','Unknown']\n",
    "explode = [0,0,0,0]\n",
    "\n",
    "#pie chart\n",
    "plt.figure()\n",
    "plt.pie(s_values,explode=explode,labels=s_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.xlabel(f'Formerly Smoked={fs}, Never Smoked={ns}, Smokes={s}, Unknonw={u}')\n",
    "plt.title('Smoking status of the patients')\n",
    "plt.savefig(fname='smoke_pie_all.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=0\n",
    "fs_0 = len(data.loc[(data['smoking_status']=='formerly smoked') & (data['stroke']==0)])\n",
    "ns_0 = len(data.loc[(data['smoking_status']=='never smoked') & (data['stroke']==0)])\n",
    "s_0 = len(data.loc[(data['smoking_status']=='smokes') & (data['stroke']==0)])\n",
    "u_0 = len(data.loc[(data['smoking_status']=='Unknown') & (data['stroke']==0)])\n",
    "s_values_0 = [fs_0,ns_0,s_0,u_0]\n",
    "\n",
    "plt.figure()\n",
    "plt.pie(s_values_0,explode=explode,labels=s_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.xlabel(f'Formerly Smoked={fs_0}, Never Smoked={ns_0}, Smokes={s_0}, Unknonw={u_0}')\n",
    "plt.title('Smoking status of the patients with no stroke')\n",
    "plt.savefig(fname='smoke_pie_no_Stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=1\n",
    "fs_1 = len(data.loc[(data['smoking_status']=='formerly smoked') & (data['stroke']==1)])\n",
    "ns_1 = len(data.loc[(data['smoking_status']=='never smoked') & (data['stroke']==1)])\n",
    "s_1 = len(data.loc[(data['smoking_status']=='smokes') & (data['stroke']==1)])\n",
    "u_1 = len(data.loc[(data['smoking_status']=='Unknown') & (data['stroke']==1)])\n",
    "s_values_1 = [fs_1,ns_1,s_1,u_1]\n",
    "\n",
    "plt.figure()\n",
    "plt.pie(s_values_1,explode=explode,labels=s_labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.xlabel(f'Formerly Smoked={fs_1}, Never Smoked={ns_1}, Smokes={s_1}, Unknonw={u_1}')\n",
    "plt.title('Smoking status of the patients who suffered a stroke')\n",
    "plt.savefig(fname='smoke_pie_stroke.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce052622",
   "metadata": {},
   "source": [
    "# BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5deb207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bmi weight categories for all the data\n",
    "underweight = len(data.loc[data['bmi']<=18.5])\n",
    "normal = len(data.loc[(data['bmi']>18.5) & (data['bmi']<=24.9)])\n",
    "overweight = len(data.loc[(data['bmi']>24.9) & (data['bmi']<=29.9)])\n",
    "obese = len(data.loc[(data['bmi']>29.9) & (data['bmi']<=34.9)])\n",
    "severely_obese = len(data.loc[(data['bmi']>34.9) & (data['bmi'] <= 39.9)])\n",
    "morbidly_obese = len(data.loc[data['bmi']>39.9])\n",
    "classes = [underweight,normal,overweight,obese,severely_obese,morbidly_obese]\n",
    "labels=['Under\\nweight','Normal','Over\\nweight','Obese','Severely\\nObese','Morbidly\\nObese']\n",
    "\n",
    "#bar plot of the weight classes\n",
    "plt.figure\n",
    "plt.bar(labels,classes,width=1,edgecolor='black')\n",
    "plt.xlabel('Weight Classes')\n",
    "plt.title('Weight Classes of the Patients')\n",
    "plt.savefig(fname='bmi_barplot_all.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#pie chart\n",
    "explode=[0,0,0,0,0,0]\n",
    "plt.figure()\n",
    "plt.pie(classes,explode=explode,labels=labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.xlabel(f'Underweight={underweight}, Normal={normal}, Overweight={overweight}, Obese={obese}, Severely Obese={severely_obese},Morbidly Obese={morbidly_obese}')\n",
    "plt.title('Pie chart of the weight classes of the Patients')\n",
    "plt.savefig(fname='bmi_pie_all.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=0\n",
    "underweight_0 = len(data.loc[(data['bmi']<=18.5) & (data['stroke']==0)])\n",
    "normal_0 = len(data.loc[(data['bmi']>18.5) & (data['bmi']<=24.9) & (data['stroke']==0)])\n",
    "overweight_0 = len(data.loc[(data['bmi']>24.9) & (data['bmi']<=29.9) & (data['stroke']==0)])\n",
    "obese_0 = len(data.loc[(data['bmi']>29.9) & (data['bmi']<=34.9) & (data['stroke']==0)])\n",
    "severely_obese_0 = len(data.loc[(data['bmi']>34.9) & (data['bmi'] <= 39.9) & (data['stroke']==0)])\n",
    "morbidly_obese_0 = len(data.loc[(data['bmi']>39.9) & (data['stroke']==0)])\n",
    "classes_0 = [underweight_0,normal_0,overweight_0,obese_0,severely_obese_0,morbidly_obese_0]\n",
    "\n",
    "#bar plot of the weight classes\n",
    "plt.figure\n",
    "plt.bar(labels,classes_0,width=1,edgecolor='black')\n",
    "plt.xlabel('Weight Classes')\n",
    "plt.title('Weight Classes of the Patients with no stroke')\n",
    "plt.savefig(fname='bmi_barplot_no_stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.pie(classes_0,explode=explode,labels=labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.xlabel(f'Underweight={underweight_0}, Normal={normal_0}, Overweight={overweight_0}, Obese={obese_0}, Severely Obese={severely_obese_0},Morbidly Obese={morbidly_obese_0}')\n",
    "plt.title('Pie chart of the weight classes of the Patients with no stroke')\n",
    "plt.savefig(fname='bmi_pie_no_Stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=1\n",
    "underweight_1 = len(data.loc[(data['bmi']<=18.5) & (data['stroke']==1)])\n",
    "normal_1 = len(data.loc[(data['bmi']>18.5) & (data['bmi']<=24.9) & (data['stroke']==1)])\n",
    "overweight_1 = len(data.loc[(data['bmi']>24.9) & (data['bmi']<=29.9) & (data['stroke']==1)])\n",
    "obese_1 = len(data.loc[(data['bmi']>29.9) & (data['bmi']<=34.9) & (data['stroke']==1)])\n",
    "severely_obese_1 = len(data.loc[(data['bmi']>34.9) & (data['bmi'] <= 39.9) & (data['stroke']==1)])\n",
    "morbidly_obese_1 = len(data.loc[(data['bmi']>39.9) & (data['stroke']==1)])\n",
    "classes_1 = [underweight_1,normal_1,overweight_1,obese_1,severely_obese_1,morbidly_obese_1]\n",
    "\n",
    "#bar plot of the weight classes\n",
    "plt.figure\n",
    "plt.bar(labels,classes_1,width=1,edgecolor='black')\n",
    "plt.xlabel('Weight Classes')\n",
    "plt.title('Weight Classes of the Patients who suffered a stroke')\n",
    "plt.savefig(fname='bmi_barplot_stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "explode = [0.5,0.25,0,0,0,0.25]\n",
    "plt.figure()\n",
    "plt.pie(classes_1,explode=explode,labels=labels,autopct='%1.2f%%',shadow=True)\n",
    "plt.xlabel(f'Underweight={underweight_1}, Normal={normal_1}, Overweight={overweight_1}, Obese={obese_1}, Severely Obese={severely_obese_1},Morbidly Obese={morbidly_obese_1}')\n",
    "plt.title('Pie chart of the weight classes of the Patients who suffered a stroke')\n",
    "plt.savefig(fname='bmi_pie_stroke.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed37453",
   "metadata": {},
   "source": [
    "# Average Glucose Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fccee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['avg_glucose_level'].min()\n",
    "#for all the data\n",
    "g_levels = data['avg_glucose_level']\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(g_levels)\n",
    "plt.xlabel('Average Glucose (mg/dl)')\n",
    "plt.title('Average Glucose Levels of the Patients')\n",
    "plt.savefig(fname='avg_hist_all.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=0\n",
    "g_levels_0 = data.loc[data['stroke']==0,'avg_glucose_level']\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(g_levels_0)\n",
    "plt.xlabel('Average Glucose (mg/dl)')\n",
    "plt.title('Average Glucose Levels of the Patients with no stroke')\n",
    "plt.savefig(fname='avg_hist_no_Stroke.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "#for the data with Stroke=1\n",
    "g_levels_1 = data.loc[data['stroke']==1,'avg_glucose_level']\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(g_levels_1)\n",
    "plt.xlabel('Average Glucose (mg/dl)')\n",
    "plt.title('Average Glucose Levels of the Patients who suffered a stroke')\n",
    "plt.savefig(fname='avg_hist_stroke.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0765c263",
   "metadata": {},
   "source": [
    "# Προετοιμασία των δεδομένων"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ace9be9",
   "metadata": {},
   "source": [
    "--> Αρχικά πρέπει να εξισσοροπήσουμε τα δεδομένα γιατί η μία κλάση έχει πολλά περισσότερα δεδομένα από την άλλη. Για να το κάνουμε αυτό χρησιμοποιούμε μια τεχνική Oversampling της κλάσης μειοψηφίας που ονομάζεται SMOTE.\n",
    "--> Επίσης τα δεδομένα περιέχουν και κατηγορικά χαρακτηριστικά που δεν τα δέχονται οι αλγόριθμοι που θα χρησιμοποιήσουμε. Εδώ υπάρχουν δύο τρόποι αντιμετώπισης. Ο πρώτος είναι να διώξουμε αυτά τα κατηγορικά χαρακτηριστικά και ο δεύτερος είναι να εφαρμόσουμε μια τεχνική που λέγεται One Hot Encoding και να τα μετατρέψουμε σε αριθμητικά. Θα εφαρμόσουμε και τις δύο μεθόδους ώστε να δούμε πώς επηρεάζεται κάθε φορά η απόδοση του μοντέλου.\n",
    "--> Τέλος θα κανονικοποιήσουμε τα δεδομένα πριν τα χρησιμοποιήσουμε στους αλγορίθμους ταξινόμησης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c43e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the irrelevant column INDEX\n",
    "data.drop(columns=['index'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38123b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing some categorical attributes to 0 and 1 because the algorithms we use cant support categorical values\n",
    "data['gender']=data['gender'].apply(lambda x : 1 if x=='Male' else 0) \n",
    "data[\"Residence_type\"] = data[\"Residence_type\"].apply(lambda x: 1 if x==\"Urban\" else 0)\n",
    "data[\"ever_married\"] = data[\"ever_married\"].apply(lambda x: 1 if x==\"Yes\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec32266b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the new form of the data set\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e152c78",
   "metadata": {},
   "source": [
    "## Περίπτωση δεδομένων όπου έχουμε διαγράψει τις κατηγορικές στήλες."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314c9e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data without the Categorical attributes Work Type and Smoking Status\n",
    "X = data.drop(columns=['stroke']) #removing the labels from the data set\n",
    "#dropping the categorical attributes\n",
    "X.drop(columns=['work_type'],inplace=True)\n",
    "X.drop(columns=['smoking_status'],inplace=True)\n",
    "#class labels of the data\n",
    "y = data['stroke']\n",
    "\n",
    "print('Before oversampling')\n",
    "print(f'Shape of the data set: {X.shape}')\n",
    "print(f'Shape of the class labels list: {y.shape}')\n",
    "\n",
    "#showing the first five rows of the new data set\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balancing the Data using SMOTE\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "print('After oversampling')\n",
    "print(f'Shape of the data set: {X.shape}')\n",
    "print(f'Shape of the class labels list: {y.shape}')\n",
    "print(f'Number of records with Stroke=0: {len(y.loc[y==0])}')\n",
    "print(f'Number of records with Stroke=1: {len(y.loc[y==1])}')\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6e0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into Train and Test datasets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y,random_state=0)\n",
    "\n",
    "print(f'Sizes: \\nX_train={X_train.shape},\\nX_test={X_test.shape},\\nY_train={Y_train.shape},\\nY_test={Y_test.shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8104bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the data using Standard scaler\n",
    "sc = StandardScaler() #initializing a StandardScaler class instance\n",
    "#applying the normalization\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df46dfd",
   "metadata": {},
   "source": [
    "## Περίπτωση των δεδομένων που εφαρμόζουμε One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319867d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying one hot encoding to the attributes Work Type and Smoking Status\n",
    "one_hot = data[['smoking_status','work_type']]\n",
    "one_hot = pd.get_dummies(one_hot)\n",
    "one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the categorical columns and the class labels\n",
    "Xoh = data.drop(columns=['stroke','smoking_status','work_type'])\n",
    "#merging the one hot into the dataset\n",
    "Xoh = Xoh.merge(one_hot,left_index=True,right_index=True,how='left') \n",
    "#class labels of the data\n",
    "yoh = data['stroke']\n",
    "\n",
    "print('Before oversampling')\n",
    "print(f'Shape of the data set: {Xoh.shape}')\n",
    "print(f'Shape of the class labels list: {yoh.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b504dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#balancing the data using smote\n",
    "oversample = SMOTE()\n",
    "Xoh, yoh = oversample.fit_resample(Xoh, yoh)\n",
    "\n",
    "print('After oversampling')\n",
    "print(f'Shape of the data set: {Xoh.shape}')\n",
    "print(f'Shape of the class labels list: {yoh.shape}')\n",
    "print(f'Number of records with Stroke=0: {len(y.loc[yoh==0])}')\n",
    "print(f'Number of records with Stroke=1: {len(y.loc[yoh==1])}')\n",
    "\n",
    "Xoh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb63ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into Train and Test sets\n",
    "Xoh_train, Xoh_test, Yoh_train, Yoh_test = train_test_split(Xoh,yoh,random_state=0)\n",
    "\n",
    "print(f'Sizes: \\nX_train={Xoh_train.shape},\\nX_test={Xoh_test.shape},\\nY_train={Yoh_train.shape},\\nY_test={Yoh_test.shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cdc4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the data using Standard scaler\n",
    "sc = StandardScaler() #initializing a StandardScaler class instance\n",
    "#applying the normalization\n",
    "Xoh_train = sc.fit_transform(Xoh_train)\n",
    "Xoh_test = sc.transform(Xoh_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f839deb",
   "metadata": {},
   "source": [
    "Έχουμε έτοιμα τα δεδομένα με τα οποία θα δουλέψουμε, οπότε μπορούμε να αρχίσουμε να στήνουμε τα μοντέλα μας."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023ceb54",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe8949",
   "metadata": {},
   "source": [
    "### Για τα δεδομένα χωρίς τα κατηγορικά χαρακτηριστικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c91f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up and training the tree trying different max depth values so we can choose the best one\n",
    "\n",
    "depth_list = [i for i in range(1,31)] #list with the possible max depth values\n",
    "accuracy_list =[] #initializing a list for the accuracy values\n",
    "f1_score_list = [] #initializing a list for the f1 score values\n",
    "\n",
    "#training and testing trees with different max depths - Criterion = Gini\n",
    "for depth in depth_list:\n",
    "    dtree = DecisionTreeClassifier(criterion='gini',max_depth=depth,random_state=0)\n",
    "    dtree.fit(X_train,Y_train) #training\n",
    "    m_ac = dtree.score(X_test,Y_test) #mean accuracy of the tree\n",
    "    y_pred = dtree.predict(X_test) #predicted values for the test data\n",
    "    f1 = f1_score(Y_test,y_pred) #f1 score of the tree\n",
    "    f1_score_list.append(f1) #putting the f1 value in the list\n",
    "    accuracy_list.append(m_ac) #putting the accuracy value in the list\n",
    "    \n",
    "    \n",
    "#max value and index of the mean accuracy values\n",
    "ac_max_value = max(accuracy_list)\n",
    "ac_list_index = accuracy_list.index(ac_max_value)\n",
    "#max value and index of the f1 score\n",
    "max_value_f1 = max(f1_score_list)\n",
    "list_index_f1 = f1_score_list.index(max_value_f1)\n",
    "\n",
    "print(f'Gini index: Max accuracy = {ac_max_value}, Max f1 = {max_value_f1}')\n",
    "print(f'Index: {ac_list_index},{list_index_f1}')\n",
    "\n",
    "#max depth value = index + 1 cause indices start from 0 in python\n",
    "\n",
    "#plotting the result\n",
    "plt.figure\n",
    "plt.plot(depth_list,accuracy_list,label='Accuracy')\n",
    "plt.plot(ac_list_index+1,accuracy_list[ac_list_index],'o')\n",
    "plt.plot(depth_list,f1_score_list,label='F1 score')\n",
    "plt.plot(list_index_f1+1,max_value_f1,'o')\n",
    "plt.xlabel('Max depth of the Tree')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Max Depth vs Score for Gini Index')\n",
    "plt.legend()\n",
    "plt.savefig(fname='dtree_gini_depth_vs_score.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "accuracy_list_e =[] #initializing a list for the accuracy values (entropy criterion)\n",
    "f1_score_list_e = [] #initializing a list for the f1 score values (entropy criterion)\n",
    "\n",
    "#training and testing trees with different max depths - Criterion = Entropy\n",
    "for depth in depth_list:\n",
    "    dtree2 = DecisionTreeClassifier(criterion='entropy',max_depth=depth,random_state=0)\n",
    "    dtree2.fit(X_train,Y_train) #training\n",
    "    m_ac = dtree2.score(X_test,Y_test) #mean accuracy of the tree\n",
    "    y_pred = dtree2.predict(X_test) #predicted values for the test data\n",
    "    f1 = f1_score(Y_test,y_pred) #f1 score of the tree\n",
    "    f1_score_list_e.append(f1) #putting the f1 value in the list\n",
    "    accuracy_list_e.append(m_ac) #putting the accuracy value in the list\n",
    "    \n",
    "#max value and index of the mean accuracy values\n",
    "ac_max_value_e = max(accuracy_list_e)\n",
    "ac_list_index_e = accuracy_list_e.index(ac_max_value_e)\n",
    "#max value and index of the f1 score\n",
    "max_value_f1_e = max(f1_score_list_e)\n",
    "list_index_f1_e = f1_score_list_e.index(max_value_f1_e)\n",
    "\n",
    "print(f'Entropy: Max accuracy = {ac_max_value_e}, Max f1 = {max_value_f1_e}')\n",
    "print(f'Index: {ac_list_index_e},{list_index_f1_e}')\n",
    "\n",
    "#plotting the result\n",
    "plt.figure\n",
    "plt.plot(depth_list,accuracy_list_e,label='Accuracy')\n",
    "plt.plot(ac_list_index_e+1,accuracy_list_e[ac_list_index_e],'o')\n",
    "plt.plot(depth_list,f1_score_list_e,label='F1 score')\n",
    "plt.plot(list_index_f1_e+1,max_value_f1_e,'o')\n",
    "plt.xlabel('Max depth of the Tree')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Max Depth vs Score for Entropy')\n",
    "plt.legend()\n",
    "plt.savefig(fname='dtree_entropy_depth_vs_score.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870db6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training a tree with max_depth = final_depth and criterion=Gini. This is our final model of a decision tree\n",
    "final_depth = 20\n",
    "crit = 'gini'\n",
    "final_tree = DecisionTreeClassifier(criterion=crit,max_depth=final_depth,random_state=0)\n",
    "final_tree.fit(X_train,Y_train) #training\n",
    "Y_pred_final_dtree = final_tree.predict(X_test) #predicted labels for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512d4cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating evaluation metrics of our final model\n",
    "accuracy_value = final_tree.score(X_test,Y_test) #accuracy\n",
    "f1_score_value = f1_score(Y_test,Y_pred_final_dtree) #f1 score\n",
    "precision_value = precision_score(Y_test,Y_pred_final_dtree) #precision score\n",
    "recall_value = recall_score(Y_test,Y_pred_final_dtree) #recall score\n",
    "#printing the results\n",
    "print(f'Accuracy = {accuracy_value}\\nF1-score = {f1_score_value}\\nPrecision = {precision_value}\\nRecall = {recall_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900f864",
   "metadata": {},
   "source": [
    "### Για τα δεδομένα με τα κατηγορικά χαρακτηριστικά και το One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9de721",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up trees with different max depth values and using gini and Entropy\n",
    "depth_list = [i for i in range(1,31)] #list with the possible max depth values\n",
    "accuracy_list =[] #initializing a list for the accuracy values\n",
    "f1_score_list = [] #initializing a list for the f1 score values\n",
    "\n",
    "#training and testing trees with different max depths - Criterion = Gini\n",
    "for depth in depth_list:\n",
    "    dtree = DecisionTreeClassifier(criterion='gini',max_depth=depth,random_state=0)\n",
    "    dtree.fit(Xoh_train,Yoh_train) #training\n",
    "    m_ac = dtree.score(Xoh_test,Yoh_test) #mean accuracy of the tree\n",
    "    y_pred = dtree.predict(Xoh_test) #predicted values for the test data\n",
    "    f1 = f1_score(Yoh_test,y_pred) #f1 score of the tree\n",
    "    f1_score_list.append(f1) #putting the f1 value in the list\n",
    "    accuracy_list.append(m_ac) #putting the accuracy value in the list\n",
    "    \n",
    "    \n",
    "#max value and index of the mean accuracy values\n",
    "ac_max_value = max(accuracy_list)\n",
    "ac_list_index = accuracy_list.index(ac_max_value)\n",
    "#max value and index of the f1 score\n",
    "max_value_f1 = max(f1_score_list)\n",
    "list_index_f1 = f1_score_list.index(max_value_f1)\n",
    "\n",
    "print(f'Gini index: Max accuracy = {ac_max_value}, Max f1 = {max_value_f1}')\n",
    "print(f'Index: {ac_list_index},{list_index_f1}')\n",
    "\n",
    "#max depth value = index + 1 cause indices start from 0 in python\n",
    "\n",
    "#plotting the result\n",
    "plt.figure\n",
    "plt.plot(depth_list,accuracy_list,label='Accuracy')\n",
    "plt.plot(ac_list_index+1,accuracy_list[ac_list_index],'o')\n",
    "plt.plot(depth_list,f1_score_list,label='F1 score')\n",
    "plt.plot(list_index_f1+1,max_value_f1,'o')\n",
    "plt.xlabel('Max depth of the Tree')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Max Depth vs Score for Gini Index')\n",
    "plt.legend()\n",
    "plt.savefig(fname='dtree_gini_OH_depth_vs_score.png',format='png')\n",
    "plt.show()\n",
    "\n",
    "accuracy_list_e =[] #initializing a list for the accuracy values (Criterion entropy)\n",
    "f1_score_list_e = [] #initializing a list for the f1 score values (Criterion entropy)\n",
    "\n",
    "#training and testing trees with different max depths - Criterion = Entropy\n",
    "for depth in depth_list:\n",
    "    dtree2 = DecisionTreeClassifier(criterion='entropy',max_depth=depth,random_state=0)\n",
    "    dtree2.fit(Xoh_train,Yoh_train) #training\n",
    "    m_ac = dtree2.score(Xoh_test,Yoh_test) #mean accuracy of the tree\n",
    "    y_pred = dtree2.predict(Xoh_test) #predicted values for the test data\n",
    "    f1 = f1_score(Yoh_test,y_pred) #f1 score of the tree\n",
    "    f1_score_list_e.append(f1) #putting the f1 value in the list\n",
    "    accuracy_list_e.append(m_ac) #putting the accuracy value in the list\n",
    "    \n",
    "#max value and index of the mean accuracy values\n",
    "ac_max_value = max(accuracy_list_e)\n",
    "ac_list_index = accuracy_list_e.index(ac_max_value)\n",
    "#max value and index of the f1 score\n",
    "max_value_f1 = max(f1_score_list_e)\n",
    "list_index_f1 = f1_score_list_e.index(max_value_f1)\n",
    "\n",
    "print(f'Entropy: Max accuracy = {ac_max_value}, Max f1 = {max_value_f1}')\n",
    "print(f'Index: {ac_list_index},{list_index_f1}')\n",
    "\n",
    "#plotting the result\n",
    "plt.figure\n",
    "plt.plot(depth_list,accuracy_list_e,label='Accuracy')\n",
    "plt.plot(ac_list_index+1,accuracy_list_e[ac_list_index],'o')\n",
    "plt.plot(depth_list,f1_score_list_e,label='F1 score')\n",
    "plt.plot(list_index_f1+1,max_value_f1,'o')\n",
    "plt.xlabel('Max depth of the Tree')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Max Depth vs Score for Entropy')\n",
    "plt.legend()\n",
    "plt.savefig(fname='dtree_entropy_OH_depth_vs_score.png',format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974c268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training a tree with max_depth = final_depth and criterion=gini. This is our final model of a decision tree\n",
    "depth = 18\n",
    "crit = 'gini'\n",
    "final_tree_OH = DecisionTreeClassifier(criterion=crit,max_depth=depth,random_state=0)\n",
    "final_tree_OH.fit(Xoh_train,Yoh_train) #training\n",
    "Yoh_pred_final_dtree = final_tree_OH.predict(Xoh_test) #predicted labels for the test data\n",
    "\n",
    "#Calculating evaluation metrics of our final model\n",
    "accuracy_value_OH = final_tree_OH.score(Xoh_test,Yoh_test) #accuracy\n",
    "f1_score_value_OH = f1_score(Yoh_test,Yoh_pred_final_dtree) #f1 score\n",
    "precision_value_OH = precision_score(Yoh_test,Yoh_pred_final_dtree) #precision score\n",
    "recall_value_OH = recall_score(Yoh_test,Yoh_pred_final_dtree) #recall score\n",
    "#printing the results\n",
    "print(f'Accuracy = {accuracy_value_OH}\\nF1-score = {f1_score_value_OH}\\nPrecision = {precision_value_OH}\\nRecall = {recall_value_OH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0c5e5c",
   "metadata": {},
   "source": [
    "# Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8c7cb4",
   "metadata": {},
   "source": [
    "## Για τα δεδομένα χωρίς τα κατηγορικά χαρακτηριστικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3bc775",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing an instance of the Gaussian Naive Bayes class\n",
    "gauss_model = GaussianNB()\n",
    "#training the gaussian naive bayes model with the train data set\n",
    "gauss_model.fit(X_train, Y_train)\n",
    "#predicting the labels of the test data set\n",
    "Y_pred_final_GNB = gauss_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7249524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating evaluation metrics of our final model\n",
    "accuracy_value = gauss_model.score(X_test,Y_test) #accuracy\n",
    "f1_score_value = f1_score(Y_test,Y_pred_final_GNB) #f1 score\n",
    "precision_value = precision_score(Y_test,Y_pred_final_GNB) #precision score\n",
    "recall_value = recall_score(Y_test,Y_pred_final_GNB) #recall score\n",
    "#printing the results\n",
    "print(f'Accuracy = {accuracy_value}\\nF1-score = {f1_score_value}\\nPrecision = {precision_value}\\nRecall = {recall_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d4edd8",
   "metadata": {},
   "source": [
    "## Για τα δεδομένα με τα κατηγορικά χαρακτηριστικά και το One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f5676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying Gaussian naive bayes to the new data set after the one hot encoding\n",
    "gauss_model2 = GaussianNB()\n",
    "gauss_model2.fit(Xoh_train, Yoh_train) #training\n",
    "#predicting the labels of the test data set\n",
    "Yoh_pred_final_GNB = gauss_model2.predict(Xoh_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e431fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating evaluation metrics of our final model\n",
    "accuracy_value_OH = gauss_model2.score(Xoh_test,Yoh_test) #accuracy\n",
    "f1_score_value_OH = f1_score(Yoh_test,Yoh_pred_final_GNB) #f1 score\n",
    "precision_value_OH = precision_score(Yoh_test,Yoh_pred_final_GNB) #precision score\n",
    "recall_value_OH = recall_score(Yoh_test,Yoh_pred_final_GNB) #recall score\n",
    "#printing the results\n",
    "print(f'Accuracy = {accuracy_value_OH}\\nF1-score = {f1_score_value_OH}\\nPrecision = {precision_value_OH}\\nRecall = {recall_value_OH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d415bbb6",
   "metadata": {},
   "source": [
    "Παρατηρούμε ότι η ακρίβεια και το μέτρο f1 μειώθηκαν. Άρχισε να φαίνεται η επίδραση της αύξησης του αριθμού των predictor λόγω του one hot encoding στο αποτέλεσμα. Λεπτομέρειες στην τεχνική έκθεση που συνοδεύει τον κώδικα."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33705561",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17521b72",
   "metadata": {},
   "source": [
    "## Για τα δεδομένα χωρίς τα κατηγορικά χαρακτηριστικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbab83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training a Knn classifier with k = 5 for two different metrics\n",
    "p_metrics = [1,2] #p=1 Cityblock distance, p=2 Euclidean distance\n",
    "\n",
    "for p_value in p_metrics:\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = p_value) #class instance\n",
    "    knn.fit(X_train,Y_train) #training the model with the train data set\n",
    "    y_pred = knn.predict(X_test) #predicting the classes for the test data set\n",
    "    acc = knn.score(X_test,Y_test) #accuracy of the current model\n",
    "    f1 = f1_score(Y_test,y_pred) #f1 score of the current model\n",
    "    if p_value == 1:\n",
    "        print('For the Cityblock distance:\\n')\n",
    "        print(f'Accuracy = {acc}\\nF1-score = {f1}\\n')\n",
    "    else:\n",
    "        print('For the Euclidean distance:\\n')\n",
    "        print(f'Accuracy = {acc}\\nF1-score = {f1}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7ad487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the final model with k=5\n",
    "knn_final = KNeighborsClassifier(n_neighbors = 5,metric='minkowski',p=2) #initializing an instance of the knn class\n",
    "knn_final.fit(X_train,Y_train) #training the model\n",
    "Y_pred_final_knn = knn_final.predict(X_test) #predicting the class labels for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2d0cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating evaluation metrics for our final model\n",
    "accuracy_value_knn = knn_final.score(X_test,Y_test) #accuracy\n",
    "f1_score_value_knn = f1_score(Y_test,Y_pred_final_knn) #f1 score\n",
    "precision_value_knn = precision_score(Y_test,Y_pred_final_knn) #precision\n",
    "recall_value_knn = recall_score(Y_test,Y_pred_final_knn) #recall\n",
    "print('For the knn model:\\n')\n",
    "print(f'Accuracy = {accuracy_value_knn}')\n",
    "print(f'F1-score = {f1_score_value_knn}')\n",
    "print(f'Precision = {precision_value_knn}')\n",
    "print(f'Recall = {recall_value_knn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc2368",
   "metadata": {},
   "source": [
    "## Για τα δεδομένα με τα κατηγορικά χαρακτηριστικά και το One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16feb2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training a Knn classifier with k = 5 for two different metrics\n",
    "p_metrics = [1,2] #p=1 Cityblock distance, p=2 Euclidean distance\n",
    "\n",
    "for p_value in p_metrics:\n",
    "    knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = p_value) #class instance\n",
    "    knn.fit(Xoh_train,Yoh_train) #training the model with the train data set\n",
    "    y_pred = knn.predict(Xoh_test) #predicting the classes for the test data set\n",
    "    acc = knn.score(Xoh_test,Yoh_test) #accuracy of the current model\n",
    "    f1 = f1_score(Yoh_test,y_pred) #f1 score of the current model\n",
    "    if p_value == 1:\n",
    "        print('For the Cityblock distance:\\n')\n",
    "        print(f'Accuracy = {acc}\\nF1-score = {f1}\\n')\n",
    "    else:\n",
    "        print('For the Euclidean distance:\\n')\n",
    "        print(f'Accuracy = {acc}\\nF1-score = {f1}')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea645cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the final model with k=5\n",
    "knn_final_OH = KNeighborsClassifier(n_neighbors = 5,metric='minkowski',p=2) #initializing an instance of the knn class\n",
    "knn_final_OH.fit(Xoh_train,Yoh_train) #training the model\n",
    "Y_pred_final_OH_knn = knn_final_OH.predict(Xoh_test) #predicting the class labels for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c0adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating evaluation metrics for our final model\n",
    "accuracy_value_OH_knn = knn_final_OH.score(Xoh_test,Yoh_test) #accuracy\n",
    "f1_score_value_OH_knn = f1_score(Yoh_test,Y_pred_final_OH_knn) #f1 score\n",
    "precision_value_OH_knn = precision_score(Yoh_test,Y_pred_final_OH_knn) #precision\n",
    "recall_value_OH_knn = recall_score(Yoh_test,Y_pred_final_OH_knn) #recall\n",
    "print('For the knn model:\\n')\n",
    "print(f'Accuracy = {accuracy_value_OH_knn}')\n",
    "print(f'F1-score = {f1_score_value_OH_knn}')\n",
    "print(f'Precision = {precision_value_OH_knn}')\n",
    "print(f'Recall = {recall_value_OH_knn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4034cc",
   "metadata": {},
   "source": [
    "# Random Forests "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a12d5",
   "metadata": {},
   "source": [
    "## Για τα δεδομένα χωρίς τα κατηγορικά χαρακτηριστικά"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4035d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final Random Forest model with 200 estimators\n",
    "rf_final = RandomForestClassifier(n_estimators = 200, criterion = 'gini',max_features=None, random_state = 0) #initializing a Random Forest \n",
    "rf_final.fit(X_train,Y_train) #training the model\n",
    "Y_pred_final_RF = rf_final.predict(X_test) #predciting the class labels for the Test data\n",
    "\n",
    "#calculating some evaluation metrics for our model\n",
    "accuracy_value_RF = rf_final.score(X_test,Y_test) #accuracy\n",
    "f1_score_value_RF = f1_score(Y_test,Y_pred_final_RF) #f1 score\n",
    "precision_value_RF = precision_score(Y_test,Y_pred_final_RF) #precision\n",
    "recall_value_RF = recall_score(Y_test,Y_pred_final_RF) #recall\n",
    "\n",
    "print('For the Random Forest model:')\n",
    "print(f'Accuracy = {accuracy_value_RF}')\n",
    "print(f'F1-score = {f1_score_value_RF}')\n",
    "print(f'Precision = {precision_value_RF}')\n",
    "print(f'Recall = {recall_value_RF}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45857424",
   "metadata": {},
   "source": [
    "## Για τα δεδομένα με τα κατηγορικά χαρακτηριστικά και το One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Random Forest model for the One Hot data with 200 estimators and gini criterion\n",
    "rf_final_OH = RandomForestClassifier(n_estimators = 200, criterion = 'gini',max_features=None, random_state = 0) #initializing a Random Forest \n",
    "rf_final_OH.fit(Xoh_train,Yoh_train) #training the model\n",
    "Y_pred_final_RF_OH = rf_final_OH.predict(Xoh_test) #predciting the class labels for the Test data\n",
    "\n",
    "#calculating some evaluation metrics for our model\n",
    "accuracy_value_RF_OH = rf_final_OH.score(Xoh_test,Yoh_test) #accuracy\n",
    "f1_score_value_RF_OH = f1_score(Yoh_test,Y_pred_final_RF_OH) #f1 score\n",
    "precision_value_RF_OH = precision_score(Yoh_test,Y_pred_final_RF_OH) #precision\n",
    "recall_value_RF_OH = recall_score(Yoh_test,Y_pred_final_RF_OH) #recall\n",
    "\n",
    "print('For the Random Forest model:')\n",
    "print(f'Accuracy = {accuracy_value_RF_OH}')\n",
    "print(f'F1-score = {f1_score_value_RF_OH}')\n",
    "print(f'Precision = {precision_value_RF_OH}')\n",
    "print(f'Recall = {recall_value_RF_OH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82630735",
   "metadata": {},
   "source": [
    "# Σύγκριση μοντέλων μέσω της καμπύλης ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4320137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the Decision Trees\n",
    "dtree_pred = final_tree.predict_proba(X_test)\n",
    "dtree_fpr, dtree_tpr, _ = roc_curve(Y_test,dtree_pred[:,1])\n",
    "\n",
    "dtree_OH_pred = final_tree_OH.predict_proba(Xoh_test)\n",
    "dtree_OH_fpr, dtree_OH_tpr, _ = roc_curve(Yoh_test,dtree_OH_pred[:,1])\n",
    "\n",
    "#For the Gaussian Naive Bayes model\n",
    "GNB_pred = gauss_model.predict_proba(X_test)\n",
    "GNB_fpr, GNB_tpr, _ = roc_curve(Y_test,GNB_pred[:,1])\n",
    "\n",
    "GNB_OH_pred = gauss_model2.predict_proba(Xoh_test)\n",
    "GNB_OH_fpr, GNB_OH_tpr, _ = roc_curve(Yoh_test,GNB_OH_pred[:,1])\n",
    "\n",
    "#For the knn model\n",
    "knn_pred = knn_final.predict_proba(X_test)\n",
    "knn_fpr, knn_tpr, _ = roc_curve(Y_test,knn_pred[:,1])\n",
    "\n",
    "knn_OH_pred = knn_final_OH.predict_proba(Xoh_test)\n",
    "knn_OH_fpr, knn_OH_tpr, _ = roc_curve(Yoh_test,knn_OH_pred[:,1])\n",
    "\n",
    "#For the Random Forest model\n",
    "rf_pred = rf_final.predict_proba(X_test)\n",
    "rf_fpr, rf_tpr, _ = roc_curve(Y_test,rf_pred[:,1])\n",
    "\n",
    "rf_OH_pred = rf_final_OH.predict_proba(Xoh_test)\n",
    "rf_OH_fpr, rf_OH_tpr, _ = roc_curve(Yoh_test,rf_OH_pred[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528dc979",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the ROC curves for all models\n",
    "plt.figure()\n",
    "plt.plot(dtree_fpr,dtree_tpr,label='Decision Tree')\n",
    "plt.plot(dtree_OH_fpr,dtree_OH_tpr,label='Decision Tree+OH')\n",
    "plt.plot(GNB_fpr,GNB_tpr,label='Gaussian Naive Bayes')\n",
    "plt.plot(GNB_OH_fpr,GNB_OH_tpr,label='Gaussian Naive Bayes+OH')\n",
    "plt.plot(knn_fpr,knn_tpr,label='kNN')\n",
    "plt.plot(knn_OH_fpr,knn_OH_tpr,label='kNN+OH')\n",
    "plt.plot(rf_fpr,rf_tpr,label='Random Forest')\n",
    "plt.plot(rf_OH_fpr,rf_OH_tpr,label='Random Forest+OH')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve of the models')\n",
    "plt.legend()\n",
    "plt.savefig(fname='ROC_curve.png',format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf439c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
